{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.2\n"
     ]
    }
   ],
   "source": [
    "#姓名：黄涛 学号：03180958\n",
    "##tensorflow环境:\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width', 'Species']\n",
      "['1', '5.1', '3.5', '1.4', '0.2', 'setosa']\n",
      "['2', '4.9', '3', '1.4', '0.2', 'setosa']\n",
      "['3', '4.7', '3.2', '1.3', '0.2', 'setosa']\n",
      "['4', '4.6', '3.1', '1.5', '0.2', 'setosa']\n",
      "['5', '5', '3.6', '1.4', '0.2', 'setosa']\n",
      "['6', '5.4', '3.9', '1.7', '0.4', 'setosa']\n",
      "['7', '4.6', '3.4', '1.4', '0.3', 'setosa']\n",
      "['8', '5', '3.4', '1.5', '0.2', 'setosa']\n",
      "['9', '4.4', '2.9', '1.4', '0.2', 'setosa']\n",
      "['10', '4.9', '3.1', '1.5', '0.1', 'setosa']\n",
      "['11', '5.4', '3.7', '1.5', '0.2', 'setosa']\n",
      "['12', '4.8', '3.4', '1.6', '0.2', 'setosa']\n",
      "['13', '4.8', '3', '1.4', '0.1', 'setosa']\n",
      "['14', '4.3', '3', '1.1', '0.1', 'setosa']\n",
      "['15', '5.8', '4', '1.2', '0.2', 'setosa']\n",
      "['16', '5.7', '4.4', '1.5', '0.4', 'setosa']\n",
      "['17', '5.4', '3.9', '1.3', '0.4', 'setosa']\n",
      "['18', '5.1', '3.5', '1.4', '0.3', 'setosa']\n",
      "['19', '5.7', '3.8', '1.7', '0.3', 'setosa']\n",
      "['20', '5.1', '3.8', '1.5', '0.3', 'setosa']\n",
      "['21', '5.4', '3.4', '1.7', '0.2', 'setosa']\n",
      "['22', '5.1', '3.7', '1.5', '0.4', 'setosa']\n",
      "['23', '4.6', '3.6', '1', '0.2', 'setosa']\n",
      "['24', '5.1', '3.3', '1.7', '0.5', 'setosa']\n",
      "['25', '4.8', '3.4', '1.9', '0.2', 'setosa']\n",
      "['26', '5', '3', '1.6', '0.2', 'setosa']\n",
      "['27', '5', '3.4', '1.6', '0.4', 'setosa']\n",
      "['28', '5.2', '3.5', '1.5', '0.2', 'setosa']\n",
      "['29', '5.2', '3.4', '1.4', '0.2', 'setosa']\n",
      "['30', '4.7', '3.2', '1.6', '0.2', 'setosa']\n",
      "['31', '4.8', '3.1', '1.6', '0.2', 'setosa']\n",
      "['32', '5.4', '3.4', '1.5', '0.4', 'setosa']\n",
      "['33', '5.2', '4.1', '1.5', '0.1', 'setosa']\n",
      "['34', '5.5', '4.2', '1.4', '0.2', 'setosa']\n",
      "['35', '4.9', '3.1', '1.5', '0.2', 'setosa']\n",
      "['36', '5', '3.2', '1.2', '0.2', 'setosa']\n",
      "['37', '5.5', '3.5', '1.3', '0.2', 'setosa']\n",
      "['38', '4.9', '3.6', '1.4', '0.1', 'setosa']\n",
      "['39', '4.4', '3', '1.3', '0.2', 'setosa']\n",
      "['40', '5.1', '3.4', '1.5', '0.2', 'setosa']\n",
      "['41', '5', '3.5', '1.3', '0.3', 'setosa']\n",
      "['42', '4.5', '2.3', '1.3', '0.3', 'setosa']\n",
      "['43', '4.4', '3.2', '1.3', '0.2', 'setosa']\n",
      "['44', '5', '3.5', '1.6', '0.6', 'setosa']\n",
      "['45', '5.1', '3.8', '1.9', '0.4', 'setosa']\n",
      "['46', '4.8', '3', '1.4', '0.3', 'setosa']\n",
      "['47', '5.1', '3.8', '1.6', '0.2', 'setosa']\n",
      "['48', '4.6', '3.2', '1.4', '0.2', 'setosa']\n",
      "['49', '5.3', '3.7', '1.5', '0.2', 'setosa']\n",
      "['50', '5', '3.3', '1.4', '0.2', 'setosa']\n",
      "['51', '7', '3.2', '4.7', '1.4', 'versicolor']\n",
      "['52', '6.4', '3.2', '4.5', '1.5', 'versicolor']\n",
      "['53', '6.9', '3.1', '4.9', '1.5', 'versicolor']\n",
      "['54', '5.5', '2.3', '4', '1.3', 'versicolor']\n",
      "['55', '6.5', '2.8', '4.6', '1.5', 'versicolor']\n",
      "['56', '5.7', '2.8', '4.5', '1.3', 'versicolor']\n",
      "['57', '6.3', '3.3', '4.7', '1.6', 'versicolor']\n",
      "['58', '4.9', '2.4', '3.3', '1', 'versicolor']\n",
      "['59', '6.6', '2.9', '4.6', '1.3', 'versicolor']\n",
      "['60', '5.2', '2.7', '3.9', '1.4', 'versicolor']\n",
      "['61', '5', '2', '3.5', '1', 'versicolor']\n",
      "['62', '5.9', '3', '4.2', '1.5', 'versicolor']\n",
      "['63', '6', '2.2', '4', '1', 'versicolor']\n",
      "['64', '6.1', '2.9', '4.7', '1.4', 'versicolor']\n",
      "['65', '5.6', '2.9', '3.6', '1.3', 'versicolor']\n",
      "['66', '6.7', '3.1', '4.4', '1.4', 'versicolor']\n",
      "['67', '5.6', '3', '4.5', '1.5', 'versicolor']\n",
      "['68', '5.8', '2.7', '4.1', '1', 'versicolor']\n",
      "['69', '6.2', '2.2', '4.5', '1.5', 'versicolor']\n",
      "['70', '5.6', '2.5', '3.9', '1.1', 'versicolor']\n",
      "['71', '5.9', '3.2', '4.8', '1.8', 'versicolor']\n",
      "['72', '6.1', '2.8', '4', '1.3', 'versicolor']\n",
      "['73', '6.3', '2.5', '4.9', '1.5', 'versicolor']\n",
      "['74', '6.1', '2.8', '4.7', '1.2', 'versicolor']\n",
      "['75', '6.4', '2.9', '4.3', '1.3', 'versicolor']\n",
      "['76', '6.6', '3', '4.4', '1.4', 'versicolor']\n",
      "['77', '6.8', '2.8', '4.8', '1.4', 'versicolor']\n",
      "['78', '6.7', '3', '5', '1.7', 'versicolor']\n",
      "['79', '6', '2.9', '4.5', '1.5', 'versicolor']\n",
      "['80', '5.7', '2.6', '3.5', '1', 'versicolor']\n",
      "['81', '5.5', '2.4', '3.8', '1.1', 'versicolor']\n",
      "['82', '5.5', '2.4', '3.7', '1', 'versicolor']\n",
      "['83', '5.8', '2.7', '3.9', '1.2', 'versicolor']\n",
      "['84', '6', '2.7', '5.1', '1.6', 'versicolor']\n",
      "['85', '5.4', '3', '4.5', '1.5', 'versicolor']\n",
      "['86', '6', '3.4', '4.5', '1.6', 'versicolor']\n",
      "['87', '6.7', '3.1', '4.7', '1.5', 'versicolor']\n",
      "['88', '6.3', '2.3', '4.4', '1.3', 'versicolor']\n",
      "['89', '5.6', '3', '4.1', '1.3', 'versicolor']\n",
      "['90', '5.5', '2.5', '4', '1.3', 'versicolor']\n",
      "['91', '5.5', '2.6', '4.4', '1.2', 'versicolor']\n",
      "['92', '6.1', '3', '4.6', '1.4', 'versicolor']\n",
      "['93', '5.8', '2.6', '4', '1.2', 'versicolor']\n",
      "['94', '5', '2.3', '3.3', '1', 'versicolor']\n",
      "['95', '5.6', '2.7', '4.2', '1.3', 'versicolor']\n",
      "['96', '5.7', '3', '4.2', '1.2', 'versicolor']\n",
      "['97', '5.7', '2.9', '4.2', '1.3', 'versicolor']\n",
      "['98', '6.2', '2.9', '4.3', '1.3', 'versicolor']\n",
      "['99', '5.1', '2.5', '3', '1.1', 'versicolor']\n",
      "['100', '5.7', '2.8', '4.1', '1.3', 'versicolor']\n",
      "['101', '6.3', '3.3', '6', '2.5', 'virginica']\n",
      "['102', '5.8', '2.7', '5.1', '1.9', 'virginica']\n",
      "['103', '7.1', '3', '5.9', '2.1', 'virginica']\n",
      "['104', '6.3', '2.9', '5.6', '1.8', 'virginica']\n",
      "['105', '6.5', '3', '5.8', '2.2', 'virginica']\n",
      "['106', '7.6', '3', '6.6', '2.1', 'virginica']\n",
      "['107', '4.9', '2.5', '4.5', '1.7', 'virginica']\n",
      "['108', '7.3', '2.9', '6.3', '1.8', 'virginica']\n",
      "['109', '6.7', '2.5', '5.8', '1.8', 'virginica']\n",
      "['110', '7.2', '3.6', '6.1', '2.5', 'virginica']\n",
      "['111', '6.5', '3.2', '5.1', '2', 'virginica']\n",
      "['112', '6.4', '2.7', '5.3', '1.9', 'virginica']\n",
      "['113', '6.8', '3', '5.5', '2.1', 'virginica']\n",
      "['114', '5.7', '2.5', '5', '2', 'virginica']\n",
      "['115', '5.8', '2.8', '5.1', '2.4', 'virginica']\n",
      "['116', '6.4', '3.2', '5.3', '2.3', 'virginica']\n",
      "['117', '6.5', '3', '5.5', '1.8', 'virginica']\n",
      "['118', '7.7', '3.8', '6.7', '2.2', 'virginica']\n",
      "['119', '7.7', '2.6', '6.9', '2.3', 'virginica']\n",
      "['120', '6', '2.2', '5', '1.5', 'virginica']\n",
      "['121', '6.9', '3.2', '5.7', '2.3', 'virginica']\n",
      "['122', '5.6', '2.8', '4.9', '2', 'virginica']\n",
      "['123', '7.7', '2.8', '6.7', '2', 'virginica']\n",
      "['124', '6.3', '2.7', '4.9', '1.8', 'virginica']\n",
      "['125', '6.7', '3.3', '5.7', '2.1', 'virginica']\n",
      "['126', '7.2', '3.2', '6', '1.8', 'virginica']\n",
      "['127', '6.2', '2.8', '4.8', '1.8', 'virginica']\n",
      "['128', '6.1', '3', '4.9', '1.8', 'virginica']\n",
      "['129', '6.4', '2.8', '5.6', '2.1', 'virginica']\n",
      "['130', '7.2', '3', '5.8', '1.6', 'virginica']\n",
      "['131', '7.4', '2.8', '6.1', '1.9', 'virginica']\n",
      "['132', '7.9', '3.8', '6.4', '2', 'virginica']\n",
      "['133', '6.4', '2.8', '5.6', '2.2', 'virginica']\n",
      "['134', '6.3', '2.8', '5.1', '1.5', 'virginica']\n",
      "['135', '6.1', '2.6', '5.6', '1.4', 'virginica']\n",
      "['136', '7.7', '3', '6.1', '2.3', 'virginica']\n",
      "['137', '6.3', '3.4', '5.6', '2.4', 'virginica']\n",
      "['138', '6.4', '3.1', '5.5', '1.8', 'virginica']\n",
      "['139', '6', '3', '4.8', '1.8', 'virginica']\n",
      "['140', '6.9', '3.1', '5.4', '2.1', 'virginica']\n",
      "['141', '6.7', '3.1', '5.6', '2.4', 'virginica']\n",
      "['142', '6.9', '3.1', '5.1', '2.3', 'virginica']\n",
      "['143', '5.8', '2.7', '5.1', '1.9', 'virginica']\n",
      "['144', '6.8', '3.2', '5.9', '2.3', 'virginica']\n",
      "['145', '6.7', '3.3', '5.7', '2.5', 'virginica']\n",
      "['146', '6.7', '3', '5.2', '2.3', 'virginica']\n",
      "['147', '6.3', '2.5', '5', '1.9', 'virginica']\n",
      "['148', '6.5', '3', '5.2', '2', 'virginica']\n",
      "['149', '6.2', '3.4', '5.4', '2.3', 'virginica']\n",
      "['150', '5.9', '3', '5.1', '1.8', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "with open(r'.\\Iris数据集\\iris.csv') as f:\n",
    "    f_csv=csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    print(headers[1:6])\n",
    "    x=[]\n",
    "    label=[]\n",
    "    for row in f_csv:\n",
    "        print(row)\n",
    "        x1=[float(i) for i in row[1:5]]\n",
    "        x.append(x1)\n",
    "        if row[5]=='setosa':\n",
    "            label.append(0)\n",
    "        elif row[5]=='versicolor':\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(2)\n",
    "    X1=np.array(x)\n",
    "    Y1=np.array(label)\n",
    "    permutation = np.random.permutation(Y1.shape[0])  # 记下第一维度的打乱顺序\n",
    "    X1= X1[permutation, :]  # 按照顺序索引\n",
    "    Y1 = Y1[permutation]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换前的一个数据: [6.3 2.8 5.1 1.5]\n",
      "转换后的一个数据: [[[6.3  6.3  6.3  1.   1.   1.   1.   1.  ]\n",
      "  [4.55 6.3  2.8  1.   1.   1.   1.   1.  ]\n",
      "  [5.7  6.3  5.1  1.   1.   1.   1.   1.  ]\n",
      "  [3.9  6.3  1.5  1.   1.   1.   1.   1.  ]]\n",
      "\n",
      " [[4.55 6.3  2.8  1.   1.   1.   1.   1.  ]\n",
      "  [2.8  2.8  2.8  1.   1.   1.   1.   1.  ]\n",
      "  [3.95 5.1  2.8  1.   1.   1.   1.   1.  ]\n",
      "  [2.15 2.8  1.5  1.   1.   1.   1.   1.  ]]\n",
      "\n",
      " [[5.7  6.3  5.1  1.   1.   1.   1.   1.  ]\n",
      "  [3.95 5.1  2.8  1.   1.   1.   1.   1.  ]\n",
      "  [5.1  5.1  5.1  1.   1.   1.   1.   1.  ]\n",
      "  [3.3  5.1  1.5  1.   1.   1.   1.   1.  ]]\n",
      "\n",
      " [[3.9  6.3  1.5  1.   1.   1.   1.   1.  ]\n",
      "  [2.15 2.8  1.5  1.   1.   1.   1.   1.  ]\n",
      "  [3.3  5.1  1.5  1.   1.   1.   1.   1.  ]\n",
      "  [1.5  1.5  1.5  1.   1.   1.   1.   1.  ]]]\n"
     ]
    }
   ],
   "source": [
    "#将一维数据转化成二维八通道数据以进行卷积\n",
    "def change1to2(X1,num):\n",
    "    X2=np.ones((num,4,4,8), dtype=float)\n",
    "    for i in range(num):\n",
    "            for j in range(3):\n",
    "                for a in range(4):\n",
    "                    for b in range(4):\n",
    "                        # print(' ')\n",
    "                        if j==0:\n",
    "                            X2[i,a,b,j]=(X1[i,a]+X1[i,b])/2\n",
    "                        elif j==1:\n",
    "                            X2[i,a,b,j]=max([X1[i,a],X1[i,b]])\n",
    "                        elif j==2:\n",
    "                            X2[i, a, b, j] =min([X1[i,a],X1[i,b]])\n",
    "                        elif j==2:\n",
    "                            X2[i, a, b, j] =abs(2*X1[i,a]-X2[i,b])\n",
    "                        elif j==2:\n",
    "                            X2[i,a,b,j] =(((X1[i,a])**2+(X1[i,b])**2)/2)**0.5\n",
    "                        elif j==2:\n",
    "                            X2[i,a,b,j] =(((X1[i,a])**5+(X1[i,b])**5)/2)**1/5\n",
    "                        elif j==2:\n",
    "                            X2[i,a,b,j] =(((X1[i,a])**10+(X1[i,b])**10)/2)**1/10\n",
    "                        else:\n",
    "                            X2[i,a,b,j] =(((X1[i,a])**100+(X1[i,b])**100)/2)**0.01\n",
    "    return X2\n",
    "X2=change1to2(X1,150)\n",
    "print('转换前的一个数据:',X1[0,:])\n",
    "print('转换后的一个数据:',X2[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAD8CAYAAAB6iWHJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANNUlEQVR4nO3db4xc9XXG8efp1iitAZnEtN7YLiTKKiiNZEytDRZS5aRQYQvJeYEq8yJGJNIqiFQkqqVErUTVd33RohScQJGCitUoNBIJteimyEREgIIDjmUbjEO6ohFe2a2DTdY2oNJ1T1/MtTXanPGfvb9772z2+5FGe2fuz/eckc3D7MydexwRAoC5fqvrBgAMJ8IBQIpwAJAiHACkCAcAKcIBQOq36/xh2x+U9C+SrpX0C0l/FhFvJ+t+IemUpDOSZiNiXZ26AJpX95XD1yT9MCLGJP2wuj/IpyPieoIBWBjqhsNmSY9V249J+mzN4wEYEq5zhqTtX0XEsr77b0fEVcm6/5T0tqSQ9I8R8ch5jjkhaUKSlv6u/+i6j1027/6G1SunlnfdQmNWLz3RdQuNODzzoa5baMTsiRM6c/odZ/su+J6D7WckrUh2/dUl9HBTRByx/XuSdtn+WUQ8ly2sguMRSVq35gPx0tOrL6HMwvDRZz7fdQuN+bv1j3fdQiO+8tTWrltoxJG///rAfRcMh4i4edA+2/9tezQijtoelXRswDGOVD+P2f6+pHFJaTgAGA5133PYKenOavtOSf86d4HtpbavOLst6U8lvVqzLoCG1Q2Hv5V0i+3/kHRLdV+2P2x7slrz+5JesL1f0kuS/i0i/r1mXQANq3WeQ0Qcl/QnyeNHJG2qtt+QtKZOHQDt4wxJACnCAUCKcACQIhwApAgHACnCAUCKcACQIhwApAgHACnCAUCKcACQIhwApAgHACnCAUCKcACQIhwApAgHACnCAUCqSDjYvtX267anbP/a1Cv3PFDtP2D7hhJ1ATSndjjYHpH0DUkbJX1C0h22PzFn2UZJY9VtQtJDdesCaFaJVw7jkqYi4o2IeF/S4+qNyeu3WdKO6NktaVk15wLAkCoRDislHe67P109dqlrAAyREuGQzdmbO4DzYtb0FtoTtvfY3vPL42dqNwdgfkqEw7Sk/oGWqyQdmccaSb1ZmRGxLiLWXf2hkQLtAZiPEuHwsqQx2x+xfZmkLeqNyeu3U9LW6lOLGyXNRMTRArUBNKTWxCtJiohZ21+S9LSkEUmPRsRB21+s9j8saVK9CVhTkt6VdFfdugCaVTscJCkiJtULgP7HHu7bDkn3lKgFoB2cIQkgRTgASBEOAFKEA4AU4QAgRTgASBEOAFKEA4AU4QAgRTgASBEOAFKEA4AU4QAgRTgASBEOAFKEA4AU4QAgRTgASBEOAFJtzcrcYHvG9r7qdl+JugCaU/sCs32zMm9Rbz7Fy7Z3RsRrc5Y+HxG31a0HoB0lrj59blamJNk+OytzbjhcsldOLddHn/l83cMMnbHt/9t1C43ZNn1n1y004rpvvtl1C4048V/vD9zX1qxMSVpve7/tH9j+w0EH6x+Hd+bkOwXaAzAfbc3K3CvpmohYI+lBSU8OOlj/OLyRK5cWaA/AfLQyKzMiTkbE6Wp7UtIS28sL1AbQkFZmZdpeYdvV9nhV93iB2gAa0taszNsl3W17VtJ7krZUI/IADKm2ZmVul7S9RC0A7eAMSQApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAqtQ4vEdtH7P96oD9tv1ANS7vgO0bStQF0JxSrxz+SdKt59m/UdJYdZuQ9FChugAaUiQcIuI5SSfOs2SzpB3Rs1vSMtujJWoDaEZb7zlc7Mg8xuEBQ6KtcLiYkXm9BxmHBwyFtsLhgiPzAAyXtsJhp6St1acWN0qaiYijLdUGMA9FJl7Z/o6kDZKW256W9NeSlkjnJl9NStokaUrSu5LuKlEXQHNKjcO74wL7Q9I9JWoBaAdnSAJIEQ4AUoQDgBThACBFOABIEQ4AUoQDgBThACBFOABIEQ4AUoQDgBThACBFOABIEQ4AUoQDgBThACBFOABIEQ4AUm2Nw9tge8b2vup2X4m6AJpT5BqS6o3D2y5px3nWPB8RtxWqB6BhbY3DA7DAlHrlcDHW296v3jCbbRFxMFtke0K9Ybu6+sNL9PX1j7fYYju2Td/ZdQuN+fTN+7puoREvvrW26xYa8f4/XzZwX1tvSO6VdE1ErJH0oKQnBy3sH4d35QfbzC4A/VoJh4g4GRGnq+1JSUtsL2+jNoD5aSUcbK+w7Wp7vKp7vI3aAOanrXF4t0u62/aspPckbammYAEYUm2Nw9uu3kedABYIzpAEkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKRqh4Pt1baftX3I9kHb9yZrbPsB21O2D9i+oW5dAM0qcQ3JWUl/ERF7bV8h6ae2d0XEa31rNkoaq26fkvRQ9RPAkKr9yiEijkbE3mr7lKRDklbOWbZZ0o7o2S1pme3RurUBNKfoew62r5W0VtJP5uxaKelw3/1p/XqAnD3GhO09tvecPDFbsj0Al6BYONi+XNITkr4cESfn7k7+SDq3gnF4wHAoEg62l6gXDN+OiO8lS6Ylre67v0q9gboAhlSJTyss6VuSDkXE/QOW7ZS0tfrU4kZJMxFxtG5tAM0p8br9Jkmfk/SK7bPz1/9S0h9I58bhTUraJGlK0ruS7ipQF0CDaodDRLyg/D2F/jUh6Z66tQC0hzMkAaQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwCptsbhbbA9Y3tfdbuvbl0AzWprHJ4kPR8RtxWoB6AFbY3DA7DAFB0pdZ5xeJK03vZ+9YbZbIuIgwOOMSFpQpJGrrpKX3lqa8kWh8J133yz6xYa8+Jba7tuoRGj9/+46xYa8Wa8M3BfW+Pw9kq6JiLWSHpQ0pODjtM/Dm/k8qWl2gNwiVoZhxcRJyPidLU9KWmJ7eUlagNoRivj8GyvqNbJ9nhV93jd2gCa09Y4vNsl3W17VtJ7krZUU7AADKm2xuFtl7S9bi0A7eEMSQApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAinAAkCIcAKQIBwApwgFAqsQFZj9g+yXb+6txeH+TrLHtB2xP2T5g+4a6dQE0q8QFZv9H0mci4nR1ifoXbP8gInb3rdkoaay6fUrSQ9VPAEOqxDi8ODuTQtKS6jb3ytKbJe2o1u6WtMz2aN3aAJpTaqjNSHVZ+mOSdkXE3HF4KyUd7rs/LeZpAkOtSDhExJmIuF7SKknjtj85Z0l26fp0boXtCdt7bO85c3rwHD8AzSr6aUVE/ErSjyTdOmfXtKTVffdXqTdQNzsGszKBIVDi04qrbS+rtn9H0s2SfjZn2U5JW6tPLW6UNBMRR+vWBtCcEp9WjEp6zPaIemHz3Yh4yvYXpXPj8CYlbZI0JeldSXcVqAugQSXG4R2QtDZ5/OG+7ZB0T91aANrDGZIAUoQDgBThACBFOABIEQ4AUoQDgBThACBFOABIEQ4AUoQDgBThACBFOABIEQ4AUoQDgBThACBFOABIEQ4AUoQDgBThACDV1qzMDbZnbO+rbvfVrQugWW3NypSk5yPitgL1ALSgxNWnQ9KFZmUCWGDc+2+75kF6Myt+Kuljkr4REV+ds3+DpCfUm3x1RNK2iDg44FgTkiaqux+X9HrtBi/OcklvtVSrTTyvhafN53ZNRFyd7SgSDucO1pt89X1Jfx4Rr/Y9fqWk/6t+9dgk6R8iYqxY4QJs74mIdV33URrPa+EZlufWyqzMiDgZEaer7UlJS2wvL1kbQFmtzMq0vcK2q+3xqu7xurUBNKetWZm3S7rb9qyk9yRtiZK/z5TxSNcNNITntfAMxXMr+p4DgN8cnCEJIEU4AEgt+nCwfavt121P2f5a1/2UYvtR28dsv3rh1QuH7dW2n7V9qDpd/96ueyrhYr6G0HpPi/k9h+pN1J9LukW9E7RelnRHRLzWaWMF2P5j9c5c3RERn+y6n1Jsj0oajYi9tq9Q7+S7zy70v7Pq07yl/V9DkHRv8jWE1iz2Vw7jkqYi4o2IeF/S45I2d9xTERHxnKQTXfdRWkQcjYi91fYpSYckrey2q/qiZ6i+hrDYw2GlpMN996f1G/APbbGwfa2ktZJ+0m0nZdgesb1P0jFJuyKi0+e12MPByWOL9/esBcT25ep9X+fLEXGy635KiIgzEXG9pFWSxm13+uvgYg+HaUmr++6vUu+LYRhi1e/kT0j6dkR8r+t+Shv0NYS2LfZweFnSmO2P2L5M0hZJOzvuCedRvXH3LUmHIuL+rvsp5WK+htC2RR0OETEr6UuSnlbvja3vDvoq+UJj+zuSXpT0cdvTtr/QdU+F3CTpc5I+03dlsU1dN1XAqKRnbR9Q739auyLiqS4bWtQfZQIYbFG/cgAwGOEAIEU4AEgRDgBShAOAFOEAIEU4AEj9P4tYLuW1mVp9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#可以看一下二维一个数据每一个通道的图像（虽然没什么实际意义）\n",
    "for i in range(3):\n",
    "    plt.imshow(X2[9, :, :, i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据的label进行one-hot 编码\n",
    "Y2 = np.zeros((150, 3), dtype=float)\n",
    "for i in range(150):\n",
    "    if Y1[i]==0:\n",
    "        Y2[i,0]=1\n",
    "    elif Y1[i]==1:\n",
    "        Y2[i,1]=1\n",
    "    else :\n",
    "        Y2[i,2]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#题目里的意思应该是不分训练集和测试集，但是这样很可能过拟合，而且我就算分了也能跑到100%的准确率，所以无伤大雅\n",
    "X2_train=X2[:140,:,:,:]\n",
    "Y2_train=Y2[:140,:]\n",
    "X2_test=X2[140:,:,:,:]\n",
    "Y2_test=Y2[140:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
    "y_ = tf.placeholder(tf.float32, [None, 3])\n",
    "x_image = tf.placeholder(tf.float32, [None, 4,4,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一个卷积层+relu+池化\n",
    "W_conv1 = weight_variable([2, 2, 8, 16])\n",
    "b_conv1 = bias_variable([16])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool(h_conv1)\n",
    "#第二个卷积层+relu+池化\n",
    "W_conv2 = weight_variable([2, 2, 16, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool(h_conv2)\n",
    "#全连接+relu\n",
    "W_fc1 = weight_variable([4 *4 * 64, 32])\n",
    "b_fc1 = bias_variable([32])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 4 * 4 *64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "#全连接+softmax\n",
    "W_fc2 = weight_variable([32, 3])\n",
    "b_fc2 = bias_variable([3])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv),reduction_indices=[1]))\n",
    "#使用Adam优化器\n",
    "train_step = tf.train.AdamOptimizer(0.5e-4).minimize(cross_entropy)\n",
    "#这里是取y_conv中最大的标签值和y_中的最大标签值比较，如果相等就置1\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "#因为是三分类问题，准确率就等于判对的除以总数，即下面\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "predictxl=tf.argmax(y_conv,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.342857  test accuracy 0.2\n",
      "step 100, training accuracy 0.685714  test accuracy 0.5\n",
      "step 200, training accuracy 0.85  test accuracy 0.8\n",
      "step 300, training accuracy 0.95  test accuracy 1\n",
      "step 400, training accuracy 0.964286  test accuracy 1\n",
      "step 500, training accuracy 0.957143  test accuracy 1\n",
      "step 600, training accuracy 0.957143  test accuracy 1\n",
      "step 700, training accuracy 0.957143  test accuracy 1\n",
      "step 800, training accuracy 0.957143  test accuracy 1\n",
      "step 900, training accuracy 0.957143  test accuracy 1\n",
      "step 1000, training accuracy 0.957143  test accuracy 1\n",
      "step 1100, training accuracy 0.957143  test accuracy 1\n",
      "step 1200, training accuracy 0.957143  test accuracy 1\n",
      "step 1300, training accuracy 0.957143  test accuracy 1\n",
      "step 1400, training accuracy 0.957143  test accuracy 1\n",
      "step 1500, training accuracy 0.957143  test accuracy 1\n",
      "step 1600, training accuracy 0.971429  test accuracy 1\n",
      "step 1700, training accuracy 0.971429  test accuracy 1\n",
      "step 1800, training accuracy 0.971429  test accuracy 1\n",
      "step 1900, training accuracy 0.971429  test accuracy 1\n",
      "step 2000, training accuracy 0.971429  test accuracy 1\n",
      "step 2100, training accuracy 0.978571  test accuracy 1\n",
      "step 2200, training accuracy 0.978571  test accuracy 1\n",
      "step 2300, training accuracy 0.978571  test accuracy 1\n",
      "step 2400, training accuracy 0.978571  test accuracy 1\n",
      "step 2500, training accuracy 0.978571  test accuracy 1\n",
      "step 2600, training accuracy 0.985714  test accuracy 1\n",
      "step 2700, training accuracy 0.985714  test accuracy 1\n",
      "step 2800, training accuracy 0.985714  test accuracy 1\n",
      "step 2900, training accuracy 0.985714  test accuracy 1\n",
      "step 3000, training accuracy 0.985714  test accuracy 1\n",
      "step 3100, training accuracy 0.985714  test accuracy 1\n",
      "step 3200, training accuracy 0.985714  test accuracy 1\n",
      "step 3300, training accuracy 0.985714  test accuracy 1\n",
      "step 3400, training accuracy 0.985714  test accuracy 1\n",
      "step 3500, training accuracy 0.985714  test accuracy 1\n",
      "step 3600, training accuracy 0.985714  test accuracy 1\n",
      "step 3700, training accuracy 0.985714  test accuracy 1\n",
      "step 3800, training accuracy 0.985714  test accuracy 1\n",
      "step 3900, training accuracy 0.985714  test accuracy 1\n",
      "step 4000, training accuracy 0.985714  test accuracy 1\n",
      "step 4100, training accuracy 0.985714  test accuracy 1\n",
      "step 4200, training accuracy 0.985714  test accuracy 1\n",
      "step 4300, training accuracy 0.985714  test accuracy 1\n",
      "step 4400, training accuracy 0.985714  test accuracy 1\n",
      "step 4500, training accuracy 0.985714  test accuracy 1\n",
      "step 4600, training accuracy 0.985714  test accuracy 1\n",
      "step 4700, training accuracy 0.985714  test accuracy 1\n",
      "step 4800, training accuracy 0.985714  test accuracy 1\n",
      "step 4900, training accuracy 0.985714  test accuracy 1\n",
      "step 5000, training accuracy 0.985714  test accuracy 1\n",
      "step 5100, training accuracy 0.985714  test accuracy 1\n",
      "step 5200, training accuracy 0.985714  test accuracy 1\n",
      "step 5300, training accuracy 0.985714  test accuracy 1\n",
      "step 5400, training accuracy 0.985714  test accuracy 1\n",
      "step 5500, training accuracy 0.985714  test accuracy 1\n",
      "step 5600, training accuracy 0.985714  test accuracy 1\n",
      "step 5700, training accuracy 0.985714  test accuracy 1\n",
      "step 5800, training accuracy 0.985714  test accuracy 1\n",
      "step 5900, training accuracy 0.985714  test accuracy 1\n",
      "step 6000, training accuracy 0.985714  test accuracy 1\n",
      "step 6100, training accuracy 0.985714  test accuracy 1\n",
      "step 6200, training accuracy 0.985714  test accuracy 1\n",
      "step 6300, training accuracy 0.985714  test accuracy 1\n",
      "step 6400, training accuracy 0.985714  test accuracy 1\n",
      "step 6500, training accuracy 0.985714  test accuracy 1\n",
      "step 6600, training accuracy 0.985714  test accuracy 1\n",
      "step 6700, training accuracy 0.985714  test accuracy 1\n",
      "step 6800, training accuracy 0.985714  test accuracy 1\n",
      "step 6900, training accuracy 0.985714  test accuracy 1\n",
      "step 7000, training accuracy 0.985714  test accuracy 1\n",
      "step 7100, training accuracy 0.985714  test accuracy 1\n",
      "step 7200, training accuracy 0.985714  test accuracy 1\n",
      "step 7300, training accuracy 0.985714  test accuracy 1\n",
      "step 7400, training accuracy 0.985714  test accuracy 1\n",
      "step 7500, training accuracy 1  test accuracy 1\n",
      "step 7600, training accuracy 1  test accuracy 1\n",
      "step 7700, training accuracy 1  test accuracy 1\n",
      "step 7800, training accuracy 1  test accuracy 1\n",
      "step 7900, training accuracy 1  test accuracy 1\n",
      "the last train accuracy 1\n",
      "the last test accuracy 1\n"
     ]
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "for i in range(8000):\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x_image: X2_train, y_: Y2_train})\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy),end='  ')\n",
    "        print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n",
    "            x_image: X2_test, y_: Y2_test\n",
    "        }))\n",
    "    train_step.run(feed_dict={x_image: X2_train, y_: Y2_train})\n",
    "\n",
    "print(\"the last train accuracy %g\" % accuracy.eval(feed_dict={\n",
    "    x_image: X2_train, y_: Y2_train\n",
    "}))\n",
    "print(\"the last test accuracy %g\" % accuracy.eval(feed_dict={\n",
    "    x_image: X2_test, y_: Y2_test\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请依次输入Sepal.Length, Sepal.Width, Petal.Length, Petal.Width（用空格隔开）5.1 3.5 1.4 0.2\n",
      "Species:setosa\n"
     ]
    }
   ],
   "source": [
    "#预测\n",
    "def predicttoword(predict):\n",
    "    if predict==0:\n",
    "        print('Species:setosa')\n",
    "    elif predict==1:\n",
    "        print('Species:versicolor')\n",
    "    else:\n",
    "        print('Species:virginica')\n",
    "list=input('请依次输入Sepal.Length, Sepal.Width, Petal.Length, Petal.Width（用空格隔开）').split()\n",
    "predict_X=(np.array([float(i) for i in list])).reshape(-1,4)\n",
    "predict_X2=change1to2(predict_X,1)\n",
    "predict= predictxl.eval(feed_dict={x_image: predict_X2})\n",
    "predicttoword(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
